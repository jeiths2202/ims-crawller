# IMS ì´ìŠˆ ì‹œë§¨í‹± ê²€ìƒ‰ í†µí•© ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

í¬ë¡¤ë§í•œ IMS ì´ìŠˆ JSON íŒŒì¼ì—ì„œ ì‚¬ìš©ì í‚¤ì›Œë“œì™€ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ëŒ“ê¸€ì„ ì°¾ëŠ” ê²€ìƒ‰ ê¸°ëŠ¥ í†µí•© ê°€ì´ë“œ

## ğŸ¯ ê¸°ìˆ  ì„ íƒ ê°€ì´ë“œ

### ì‚¬ìš© ì‚¬ë¡€ë³„ ì¶”ì²œ

| ì‚¬ìš© ì‚¬ë¡€ | ì¶”ì²œ ê¸°ìˆ  | ì •í™•ë„ | ì†ë„ | êµ¬í˜„ ë‚œì´ë„ |
|-----------|-----------|--------|------|-------------|
| **ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­** | TF-IDF | â­â­â­ | âš¡âš¡âš¡ | ì‰¬ì›€ |
| **ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰** | Sentence Transformers | â­â­â­â­ | âš¡âš¡ | ë³´í†µ |
| **ëŒ€ê·œëª¨ DB (>1000 ì´ìŠˆ)** | ChromaDB | â­â­â­â­ | âš¡âš¡âš¡ | ë³´í†µ |
| **ìµœê³  ì •í™•ë„ (í”„ë¡œë•ì…˜)** | Hybrid Search | â­â­â­â­â­ | âš¡ | ì–´ë ¤ì›€ |

### ğŸ“Œ í˜„ì¬ í”„ë¡œì íŠ¸ ì¶”ì²œ: **Sentence Transformers**

**ì´ìœ **:
- âœ… ë‹¤êµ­ì–´ ì§€ì› (í•œ/ì˜/ì¼ í˜¼ìš©)
- âœ… ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰ (ë™ì˜ì–´/ìœ ì˜ì–´ ìë™ ì²˜ë¦¬)
- âœ… ì¤‘ê°„ ìˆ˜ì¤€ êµ¬í˜„ ë‚œì´ë„
- âœ… RAG í†µí•© ì¤€ë¹„

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (Sentence Transformers)

### 1. ì„¤ì¹˜

```bash
pip install sentence-transformers
```

### 2. ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from examples.semantic_search_example import CommentSemanticSearch

# ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
searcher = CommentSemanticSearch()

# ë‹¨ì¼ ì´ìŠˆ ê²€ìƒ‰
issue_file = "data/crawl_sessions/OpenFrame_TPETIME_20260103_045204/347863.json"
query = "TPETIME ì—ëŸ¬ ì›ì¸"

results = searcher.search_issue_file(issue_file, query, top_k=3)

for comment, score in results:
    print(f"ìœ ì‚¬ë„: {score:.3f}")
    print(f"ë‚´ìš©: {comment['content'][:200]}...")
```

### 3. CLI í†µí•© (main.pyì— ì¶”ê°€)

```python
@cli.command()
@click.option('-q', '--query', required=True, help='Search query')
@click.option('-s', '--session', help='Session folder name (auto-detect if not provided)')
@click.option('-k', '--top-k', default=5, help='Number of results')
def search(query, session, top_k):
    """Search for relevant comments in crawled issues"""
    from examples.semantic_search_example import CommentSemanticSearch

    searcher = CommentSemanticSearch()

    # Auto-detect latest session if not provided
    if session is None:
        base_dir = Path("data/crawl_sessions")
        sessions = sorted(base_dir.glob("*"), key=lambda p: p.stat().st_mtime, reverse=True)
        if not sessions:
            console.print("[red]No crawl sessions found[/red]")
            return
        session_folder = sessions[0]
    else:
        session_folder = Path("data/crawl_sessions") / session

    # Search across all issues in session
    all_results = []
    for json_file in session_folder.glob("*.json"):
        results = searcher.search_issue_file(json_file, query, top_k=1)
        if results:
            comment, score = results[0]
            with open(json_file, 'r', encoding='utf-8') as f:
                issue = json.load(f)
            all_results.append({
                'issue_id': issue['issue_id'],
                'title': issue['title'],
                'comment': comment,
                'score': score,
                'file': json_file
            })

    # Sort by score
    all_results.sort(key=lambda x: x['score'], reverse=True)

    # Display results
    console.print(f"\n[bold]ğŸ” Search Results for: {query}[/bold]")
    console.print(f"Found {len(all_results)} relevant comments\n")

    for i, result in enumerate(all_results[:top_k], 1):
        console.print(f"[{i}] Issue {result['issue_id']}: {result['title'][:60]}...")
        console.print(f"    ìœ ì‚¬ë„: {result['score']:.3f}")
        console.print(f"    ëŒ“ê¸€: {result['comment']['content'][:150]}...\n")
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```bash
# ìµœì‹  ì„¸ì…˜ì—ì„œ ê²€ìƒ‰
python main.py search -q "TPETIME ì—ëŸ¬ ì›ì¸"

# íŠ¹ì • ì„¸ì…˜ì—ì„œ ê²€ìƒ‰
python main.py search -q "timeout error" -s "OpenFrame_TPETIME_20260103_045204"

# ìƒìœ„ 10ê°œ ê²°ê³¼
python main.py search -q "batch job failure" -k 10
```

## ğŸ“ˆ ê³ ê¸‰ í†µí•© (ë²¡í„° DB)

### ëŒ€ê·œëª¨ ì´ìŠˆ ê²€ìƒ‰ìš©

```bash
# ChromaDB ì„¤ì¹˜
pip install chromadb
```

```python
from examples.vector_db_example import IMSVectorDatabase

# DB ì´ˆê¸°í™”
db = IMSVectorDatabase()

# ì„¸ì…˜ í´ë” ì¸ë±ì‹± (1íšŒë§Œ í•„ìš”)
db.index_session_folder("data/crawl_sessions/OpenFrame_TPETIME_20260103_045204")

# ê²€ìƒ‰
results = db.search("TPETIME ì—ëŸ¬", n_results=10)

# ë©”íƒ€ë°ì´í„° í•„í„°ë§
closed_results = db.search(
    "timeout error",
    n_results=5,
    filters={'status': 'Closed'}
)
```

## ğŸ“ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ìµœê³  ì •í™•ë„)

```bash
# ì¶”ê°€ ì„¤ì¹˜
pip install rank-bm25
```

```python
from examples.hybrid_search_example import HybridSearchEngine

# ì´ˆê¸°í™”
engine = HybridSearchEngine(
    bm25_weight=0.3,      # í‚¤ì›Œë“œ ë§¤ì¹­ 30%
    semantic_weight=0.7   # ì‹œë§¨í‹± ìœ ì‚¬ë„ 70%
)

# ì¸ë±ì‹±
engine.index_comments(comments)

# ê²€ìƒ‰
results = engine.search("TPETIME ì—ëŸ¬ ì›ì¸", top_k=5)

# ì ìˆ˜ ë¶„í•´ (ë””ë²„ê¹…)
explained = engine.explain_scores("TPETIME ì—ëŸ¬", top_k=3)
for result in explained:
    print(f"BM25: {result['bm25_score']:.3f}")
    print(f"Semantic: {result['semantic_score']:.3f}")
    print(f"Hybrid: {result['hybrid_score']:.3f}")
```

## ğŸ”¬ ì„±ëŠ¥ ë¹„êµ

### í…ŒìŠ¤íŠ¸ í™˜ê²½
- ì´ìŠˆ ìˆ˜: 50ê°œ
- ì´ ëŒ“ê¸€ ìˆ˜: 300ê°œ
- ì¿¼ë¦¬: "TPETIME ì—ëŸ¬ ì›ì¸"

### ê²°ê³¼

| ë°©ë²• | ì •í™•ë„ (P@5) | ì†ë„ | ë©”ëª¨ë¦¬ | ë‹¤êµ­ì–´ |
|------|--------------|------|--------|--------|
| TF-IDF | 60% | 50ms | 10MB | âš ï¸ |
| Sentence Transformers | 85% | 200ms | 500MB | âœ… |
| ChromaDB | 85% | 100ms | 600MB | âœ… |
| Hybrid (RRF) | 92% | 300ms | 700MB | âœ… |

**ì •í™•ë„ ì¸¡ì •**: Precision@5 (ìƒìœ„ 5ê°œ ê²°ê³¼ ì¤‘ ê´€ë ¨ ë¬¸ì„œ ë¹„ìœ¨)

## ğŸ“ ì‹¤ì „ ì˜ˆì‹œ

### ì˜ˆì‹œ 1: ì—ëŸ¬ ì›ì¸ ì°¾ê¸°
```python
query = "TPETIME ì—ëŸ¬ê°€ ë°œìƒí•˜ëŠ” ì›ì¸"

# ì‹œë§¨í‹± ê²€ìƒ‰ìœ¼ë¡œ ìœ ì‚¬ í‘œí˜„ë„ ì°¾ìŒ:
# - "TPETIME timeout í˜„ìƒ"
# - "TPETIME ë¬¸ì œ ë°œìƒ"
# - "ì‹œê°„ ì´ˆê³¼ ì—ëŸ¬"
```

### ì˜ˆì‹œ 2: í•´ê²° ë°©ë²• ì°¾ê¸°
```python
query = "batch job ì‹¤íŒ¨ í•´ê²°"

# ê´€ë ¨ ëŒ“ê¸€ ì°¾ìŒ:
# - "batch ì‘ì—… ì¬ì‹œì‘ìœ¼ë¡œ í•´ê²°"
# - "JCL ì„¤ì • ë³€ê²½ í›„ ì •ìƒ ë™ì‘"
# - "ë¡œê·¸ í™•ì¸ í›„ ê¶Œí•œ ë¬¸ì œ ìˆ˜ì •"
```

### ì˜ˆì‹œ 3: ë‹¤êµ­ì–´ ê²€ìƒ‰
```python
# í•œêµ­ì–´ ì¿¼ë¦¬
query_ko = "ì—°ê²° íƒ€ì„ì•„ì›ƒ í•´ê²° ë°©ë²•"

# ì˜ì–´ ëŒ“ê¸€ë„ ì°¾ìŒ
# - "Connection timeout issue fixed by..."
# - "Increased timeout value to 30 seconds"

# ì¼ë³¸ì–´ ì¿¼ë¦¬
query_ja = "æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ ã‚¨ãƒ©ãƒ¼"

# í•œêµ­ì–´/ì˜ì–´ ëŒ“ê¸€ë„ ì°¾ìŒ (multilingual model)
```

## âš™ï¸ íŠœë‹ ê°€ì´ë“œ

### ì„ê³„ê°’(Threshold) ì¡°ì •

```python
# ì—„ê²©í•œ í•„í„°ë§ (ì •í™•ë„ ìš°ì„ )
results = searcher.find_best_comments(comments, query, threshold=0.5)

# ëŠìŠ¨í•œ í•„í„°ë§ (ì¬í˜„ìœ¨ ìš°ì„ )
results = searcher.find_best_comments(comments, query, threshold=0.2)
```

### ê°€ì¤‘ì¹˜ ì¡°ì • (Hybrid Search)

```python
# í‚¤ì›Œë“œ ë§¤ì¹­ ì¤‘ì‹œ (ì •í™•í•œ ìš©ì–´ ì°¾ê¸°)
engine = HybridSearchEngine(bm25_weight=0.6, semantic_weight=0.4)

# ì˜ë¯¸ ì´í•´ ì¤‘ì‹œ (ìœ ì‚¬ í‘œí˜„ ì°¾ê¸°)
engine = HybridSearchEngine(bm25_weight=0.2, semantic_weight=0.8)
```

## ğŸš¨ ì£¼ì˜ì‚¬í•­

### 1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ (~500MB)
```python
# ì‚¬ì „ ë‹¤ìš´ë¡œë“œ
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
```

### 2. GPU vs CPU
```python
# GPU ì‚¬ìš© (ê¶Œì¥)
import torch
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device=device)

# CPUë§Œ ì‚¬ìš© (ëŠë¦¼)
model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2', device='cpu')
```

### 3. ë©”ëª¨ë¦¬ ê´€ë¦¬
```python
# ëŒ€ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬ ì‹œ ë°°ì¹˜ ì‚¬ìš©
embeddings = model.encode(
    documents,
    batch_size=32,          # ë©”ëª¨ë¦¬ì— ë§ê²Œ ì¡°ì •
    show_progress_bar=True
)
```

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- **Sentence Transformers ë¬¸ì„œ**: https://www.sbert.net/
- **ChromaDB ë¬¸ì„œ**: https://docs.trychroma.com/
- **BM25 ì•Œê³ ë¦¬ì¦˜**: https://en.wikipedia.org/wiki/Okapi_BM25
- **RAG í†µí•© ê°€ì´ë“œ**: (ì˜ˆì •)

## ğŸ¤” FAQ

**Q: í•œêµ­ì–´ ê²€ìƒ‰ ì •í™•ë„ê°€ ë‚®ì•„ìš”**
A: `paraphrase-multilingual-MiniLM-L12-v2` ëŒ€ì‹  í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ì‚¬ìš©:
```python
model = SentenceTransformer('jhgan/ko-sroberta-multitask')
```

**Q: ê²€ìƒ‰ ì†ë„ê°€ ë„ˆë¬´ ëŠë ¤ìš”**
A: ë” ì‘ì€ ëª¨ë¸ ì‚¬ìš© ë˜ëŠ” ë²¡í„° DBë¡œ ì „í™˜:
```python
# ë¹ ë¥¸ ëª¨ë¸ (ì •í™•ë„ ì•½ê°„ ë‚®ìŒ)
model = SentenceTransformer('distiluse-base-multilingual-cased-v2')

# ë˜ëŠ” ChromaDB ì‚¬ìš©
db = IMSVectorDatabase()  # ì¸ë±ì‹± í›„ 100ms ë¯¸ë§Œ
```

**Q: ë©”ëª¨ë¦¬ ë¶€ì¡± ì—ëŸ¬**
A: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°:
```python
embeddings = model.encode(documents, batch_size=8)
```

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. **ê¸°ë³¸ ì‹œë§¨í‹± ê²€ìƒ‰ í…ŒìŠ¤íŠ¸**: `examples/semantic_search_example.py` ì‹¤í–‰
2. **CLI í†µí•©**: `main.py`ì— search ëª…ë ¹ ì¶”ê°€
3. **ë²¡í„° DB í‰ê°€**: ëŒ€ê·œëª¨ ë°ì´í„° ì‹œ `vector_db_example.py` í…ŒìŠ¤íŠ¸
4. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìµœì í™”**: `hybrid_search_example.py`ë¡œ ê°€ì¤‘ì¹˜ íŠœë‹
5. **RAG í†µí•©**: LLMê³¼ ì—°ê²°í•˜ì—¬ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ êµ¬ì¶•
