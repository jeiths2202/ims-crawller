"""
Vector Database Example using ChromaDB
For large-scale IMS issue search with metadata filtering
"""
import json
from pathlib import Path
from datetime import datetime
import chromadb
from chromadb.utils import embedding_functions

class IMSVectorDatabase:
    """IMS ì´ìŠˆìš© ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤"""

    def __init__(self, db_path="data/vector_db"):
        """
        Args:
            db_path: ChromaDB ì €ì¥ ê²½ë¡œ
        """
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì˜êµ¬ ì €ì¥)
        self.client = chromadb.PersistentClient(path=db_path)

        # ë‹¤êµ­ì–´ ì„ë² ë”© í•¨ìˆ˜
        self.embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name="paraphrase-multilingual-MiniLM-L12-v2"
        )

        # ì»¬ë ‰ì…˜ ìƒì„± (ë˜ëŠ” ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ)
        self.collection = self.client.get_or_create_collection(
            name="ims_comments",
            embedding_function=self.embedding_fn,
            metadata={"description": "IMS issue comments with metadata"}
        )

    def index_session_folder(self, session_folder_path):
        """
        í¬ë¡¤ë§ ì„¸ì…˜ í´ë” ì „ì²´ë¥¼ ë²¡í„° DBì— ì¸ë±ì‹±

        Args:
            session_folder_path: ì„¸ì…˜ í´ë” ê²½ë¡œ (ì˜ˆ: data/crawl_sessions/OpenFrame_...)
        """
        session_folder = Path(session_folder_path)
        indexed_count = 0

        for json_file in session_folder.glob("*.json"):
            with open(json_file, 'r', encoding='utf-8') as f:
                issue = json.load(f)

            issue_id = issue.get('issue_id')
            comments = issue.get('comments', [])

            if not comments:
                continue

            # ê° ëŒ“ê¸€ì„ ê°œë³„ ë¬¸ì„œë¡œ ì¸ë±ì‹±
            for i, comment in enumerate(comments):
                doc_id = f"{issue_id}_comment_{i}"
                content = comment.get('content', '')

                if not content:
                    continue

                # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                metadata = {
                    'issue_id': str(issue_id),
                    'title': issue.get('title', '')[:100],  # ChromaDBëŠ” ë¬¸ìì—´ ê¸¸ì´ ì œí•œ ìˆìŒ
                    'product': issue.get('product', ''),
                    'status': issue.get('status', ''),
                    'author': comment.get('author', ''),
                    'created_date': comment.get('created_date', ''),
                    'comment_index': i
                }

                # ì¸ë±ì‹±
                self.collection.add(
                    documents=[content],
                    metadatas=[metadata],
                    ids=[doc_id]
                )
                indexed_count += 1

        print(f"âœ… Indexed {indexed_count} comments from {len(list(session_folder.glob('*.json')))} issues")

    def search(self, query, n_results=10, filters=None):
        """
        ì‹œë§¨í‹± ê²€ìƒ‰ + ë©”íƒ€ë°ì´í„° í•„í„°ë§

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬ (í•œ/ì˜/ì¼ í˜¼ìš© ê°€ëŠ¥)
            n_results: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜
            filters: ë©”íƒ€ë°ì´í„° í•„í„° (ì˜ˆ: {'product': 'OpenFrame Batch', 'status': 'Closed'})

        Returns:
            List of search results with content, metadata, and distance
        """
        where_filter = filters if filters else None

        results = self.collection.query(
            query_texts=[query],
            n_results=n_results,
            where=where_filter
        )

        # ê²°ê³¼ í¬ë§·íŒ…
        formatted_results = []
        for i in range(len(results['ids'][0])):
            formatted_results.append({
                'content': results['documents'][0][i],
                'metadata': results['metadatas'][0][i],
                'distance': results['distances'][0][i],  # ë‚®ì„ìˆ˜ë¡ ìœ ì‚¬
                'similarity': 1 - results['distances'][0][i]  # 0~1ë¡œ ì •ê·œí™”
            })

        return formatted_results

    def get_stats(self):
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„"""
        count = self.collection.count()
        return {
            'total_comments': count,
            'collection_name': self.collection.name
        }


# ============================================================
# ì‚¬ìš© ì˜ˆì‹œ
# ============================================================

if __name__ == "__main__":
    # ë²¡í„° DB ì´ˆê¸°í™”
    db = IMSVectorDatabase()

    # 1. ì„¸ì…˜ í´ë” ì¸ë±ì‹±
    print("ğŸ“‚ Indexing session folder...")
    session_folder = "data/crawl_sessions/OpenFrame_TPETIME_20260103_045204"
    db.index_session_folder(session_folder)

    # í†µê³„ í™•ì¸
    stats = db.get_stats()
    print(f"\nğŸ“Š Database Stats: {stats}")

    # 2. ê¸°ë³¸ ì‹œë§¨í‹± ê²€ìƒ‰
    print("\n" + "=" * 80)
    print("ğŸ” Example 1: Basic Semantic Search")
    print("=" * 80)

    query1 = "TPETIME ì—ëŸ¬ í•´ê²° ë°©ë²•"
    results1 = db.search(query1, n_results=5)

    print(f"\nQuery: '{query1}'")
    for i, result in enumerate(results1, 1):
        print(f"\n[{i}] ìœ ì‚¬ë„: {result['similarity']:.3f}")
        print(f"ì´ìŠˆ ID: {result['metadata']['issue_id']}")
        print(f"ì œëª©: {result['metadata']['title']}")
        print(f"ì‘ì„±ì: {result['metadata']['author']}")
        print(f"ë‚´ìš©: {result['content'][:150]}...")

    # 3. ë©”íƒ€ë°ì´í„° í•„í„°ë§ ê²€ìƒ‰
    print("\n" + "=" * 80)
    print("ğŸ” Example 2: Filtered Search (Closed issues only)")
    print("=" * 80)

    query2 = "timeout error"
    results2 = db.search(
        query2,
        n_results=5,
        filters={'status': 'Closed'}  # Closed ì´ìŠˆë§Œ
    )

    print(f"\nQuery: '{query2}' (Status=Closed)")
    for i, result in enumerate(results2, 1):
        print(f"\n[{i}] ìœ ì‚¬ë„: {result['similarity']:.3f}")
        print(f"ì´ìŠˆ ID: {result['metadata']['issue_id']}")
        print(f"ìƒíƒœ: {result['metadata']['status']}")
        print(f"ë‚´ìš©: {result['content'][:150]}...")

    # 4. ì œí’ˆë³„ ê²€ìƒ‰
    print("\n" + "=" * 80)
    print("ğŸ” Example 3: Product-Specific Search")
    print("=" * 80)

    query3 = "batch job failure"
    results3 = db.search(
        query3,
        n_results=5,
        filters={'product': 'OpenFrame Batch'}
    )

    print(f"\nQuery: '{query3}' (Product=OpenFrame Batch)")
    for i, result in enumerate(results3, 1):
        print(f"\n[{i}] ìœ ì‚¬ë„: {result['similarity']:.3f}")
        print(f"ì œí’ˆ: {result['metadata']['product']}")
        print(f"ë‚´ìš©: {result['content'][:150]}...")
